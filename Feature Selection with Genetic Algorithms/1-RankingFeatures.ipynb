{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d78f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skrebate import ReliefF\n",
    "\n",
    "df = pd.read_csv('data_training.csv', parse_dates=['datetime'])\n",
    "\n",
    "train_start, train_end = '2024-01-01', '2024-03-30'\n",
    "test_start, test_end = '2024-04-01', '2024-06-30'\n",
    "\n",
    "treino = df[(df['datetime'] >= train_start) & (df['datetime'] <= train_end)].copy()\n",
    "validacao = df[(df['datetime'] >= test_start) & (df['datetime'] <= test_end)].copy()\n",
    "\n",
    "for sub_df in [treino, validacao]:\n",
    "    sub_df.drop(columns=['datetime', 'date', 'close', 'open', 'low', 'high','volume', 'average', 'amount_stock', 'id_ticker', 'business'], \n",
    "                inplace=True, errors='ignore')\n",
    "\n",
    "def remove_non_numeric(df):\n",
    "    return df.select_dtypes(include=[np.number])\n",
    "\n",
    "X_train = remove_non_numeric(treino.drop(columns=['trend']))\n",
    "y_train = treino['trend']\n",
    "\n",
    "X_valid = remove_non_numeric(validacao.drop(columns=['trend']))\n",
    "y_valid = validacao['trend']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bef7724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top Features - CFS_SubsetEval:\n",
      "['NSMA_3', 'NSMA_11', 'NSMA_5', 'NSMA_9', 'NSMA_7', 'Bands_Norm']\n",
      "\n",
      " Top Features - ClassifierAttributeEval:\n",
      "['Bands_Norm', 'NSMA_3', 'NSMA_5', 'NSMA_9', 'NSMA_11', 'NSMA_7']\n",
      "\n",
      " Top Features - CorrelationAttributeEval:\n",
      "['NSMA_3', 'NSMA_11', 'NSMA_5', 'NSMA_9', 'NSMA_7', 'Bands_Norm']\n",
      "\n",
      " Top Features - PCA:\n",
      "['NSMA_11', 'NSMA_9', 'NSMA_7', 'NSMA_5', 'NSMA_3', 'Bands_Norm']\n",
      "\n",
      " Top Features - Information_Gain:\n",
      "['NSMA_5', 'NSMA_7', 'Bands_Norm', 'NSMA_9', 'NSMA_3', 'NSMA_11']\n",
      "\n",
      " Top Features - ReliefF:\n",
      "['Bands_Norm', 'NSMA_3', 'NSMA_5', 'NSMA_7', 'NSMA_9', 'NSMA_11']\n"
     ]
    }
   ],
   "source": [
    "#Funcoes dos metodos\n",
    "\n",
    "def cfs_subset_eval(X, y):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    feature_target_corr = X.apply(lambda col: col.corr(y)).abs()\n",
    "    selected = feature_target_corr.sort_values(ascending=False).index.tolist()\n",
    "    return selected\n",
    "\n",
    "def classifier_attribute_eval(X, y):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y)\n",
    "    importances = clf.feature_importances_\n",
    "    return list(X.columns[np.argsort(importances)[::-1]])\n",
    "\n",
    "def correlation_attribute_eval(X, y):\n",
    "    corrs = X.apply(lambda col: abs(col.corr(y)))\n",
    "    return list(corrs.sort_values(ascending=False).index)\n",
    "\n",
    "def pca_ranking(X):\n",
    "    pca = PCA(n_components=min(5, X.shape[1]))\n",
    "    pca.fit(X)\n",
    "    component_weights = np.abs(pca.components_[0])\n",
    "    return list(X.columns[np.argsort(component_weights)[::-1]])\n",
    "\n",
    "def information_gain_eval(X_scaled, y):\n",
    "    info_gain = mutual_info_classif(X_scaled, y, random_state=42)\n",
    "    info_gain_series = pd.Series(info_gain, index=X_train.columns)\n",
    "    return list(info_gain_series.sort_values(ascending=False).index)\n",
    "\n",
    "def reliefF_eval(X_scaled, y):\n",
    "    relief = ReliefF(n_neighbors=100, n_features_to_select=X_train.shape[1])\n",
    "    relief.fit(X_scaled, y)\n",
    "    relief_scores = pd.Series(relief.feature_importances_, index=X_train.columns)\n",
    "    return list(relief_scores.sort_values(ascending=False).index)\n",
    "\n",
    "#ExecuÃ§Ã£o tudo\n",
    "\n",
    "rankings = {\n",
    "    \"CFS_SubsetEval\": cfs_subset_eval(X_train, y_train),\n",
    "    \"ClassifierAttributeEval\": classifier_attribute_eval(X_train, y_train),\n",
    "    \"CorrelationAttributeEval\": correlation_attribute_eval(X_train, y_train),\n",
    "    \"PCA\": pca_ranking(X_train),\n",
    "    \"Information_Gain\": information_gain_eval(X_scaled, y_train),\n",
    "    \"ReliefF\": reliefF_eval(X_scaled, y_train)\n",
    "}\n",
    "\n",
    "for method, ranking in rankings.items():\n",
    "    print(f\"\\n Top Features - {method}:\")\n",
    "    print(ranking[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7db48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
